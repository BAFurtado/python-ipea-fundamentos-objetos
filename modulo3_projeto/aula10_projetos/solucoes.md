
# Solu√ß√µes e dicas 

Este documento cont√©m **pistas, l√≥gica e snippets parciais** para os exerc√≠cios.
N√£o s√£o solu√ß√µes completas.

---

## 1. Jogo do n√∫mero secreto (0 a 100)

### Pontos cr√≠ticos
- Converter `input()` para `int`
- Evitar loop infinito
- Contar tentativas
- Tratar erro de entrada

### L√≥gica
- Gerar n√∫mero aleat√≥rio
- Loop `while`
- Compara√ß√µes sucessivas
- `break` quando acertar

```python
import random

numero = random.randint(0, 100)
tentativas = 0
```

```python
while True:
    palpite = int(input("Digite um n√∫mero: "))
    tentativas += 1
```

```python
if palpite < numero:
    print("Muito baixo")
elif palpite > numero:
    print("Muito alto")
else:
    print(f"Acertou em {tentativas} tentativas!")
    break
```

---

## 2. Fork de reposit√≥rio no GitHub

### Pontos cr√≠ticos
- Fork ‚â† clone

    * Clone cria uma c√≥pia local do reposit√≥rio para voc√™ trabalhar, mas sem rela√ß√£o direta com o projeto original.
        
    * Fork cria uma c√≥pia do reposit√≥rio na sua conta do GitHub, permitindo propor altera√ß√µes ao projeto original via pull request.

        * Fork √© pegar uma c√≥pia do caderno do colega.
        * Pull request √© levantar a m√£o e dizer:
        * ‚ÄúPosso colar essa p√°gina no caderno original?‚Äù

    * Fork √© feito no site do GitHub

- Commit antes de push
- Editar README corretamente

### Checklist l√≥gico
```text
Fork ‚Üí Clone ‚Üí Editar ‚Üí Add ‚Üí Commit ‚Üí Push
```

```bash
git add README.md
git commit -m "Inclui email institucional"
git push
```

---

## 3. Elasticidade-pre√ßo da demanda

### Pontos cr√≠ticos
- Divis√£o por zero
- Listas com tamanhos diferentes
- Classifica√ß√£o correta

### L√≥gica
- Fun√ß√£o com duas listas
- Varia√ß√µes percentuais
- Elasticidade m√©dia

```python
def elasticidade_preco(precos, quantidades):
    ...
    return elasticidade_media, classificacao
```

```python
if e > 1:
    tipo = "el√°stica"
elif e < 1:
    tipo = "inel√°stica"
else:
    tipo = "unit√°ria"
```

---

## 4. Dicion√°rio de munic√≠pios e PIB per capita

### Pontos cr√≠ticos
- Uso correto de dicion√°rios
- Fun√ß√µes `max` e `min`

```python
pib = {
    "Bras√≠lia": 85000,
    "S√£o Paulo": 70000
}
```

```python
maior = max(pib, key=pib.get)
menor = min(pib, key=pib.get)
```

---

## 5. CSV de infla√ß√£o (pandas)

### Pontos cr√≠ticos
- Caminho do arquivo
- Rolling mean
- Filtro condicional

```python
import pandas as pd

df = pd.read_csv("inflacao.csv")
```

```python
df["media_6m"] = df["inflacao"].rolling(6).mean()
```

```python
df[df["inflacao"] > limiar]
```

---

## 6. GitHub Actions ‚Äî execu√ß√£o autom√°tica

### Pontos cr√≠ticos
- Cron em UTC
- Identa√ß√£o YAML
- Checkout obrigat√≥rio

```yaml
on:
  schedule:
    - cron: "0 21 * * 5"
```

```yaml
steps:
  - uses: actions/checkout@v3
  - uses: actions/setup-python@v4
    with:
      python-version: "3.10"
  - run: python main.py
```

---

## 7. Modelo simples de pre√ßos imobili√°rios

### Pontos cr√≠ticos
- Modelo simples
- Separar treino e teste
- Explicar resultados

```python
from sklearn.linear_model import LinearRegression
```

```python
model = LinearRegression()
model.fit(X_train, y_train)
model.score(X_test, y_test)
```

---
# 7Ô∏è‚É£ Modelo simples de pre√ßos imobili√°rios 

---

##  Objetivo

Construir um modelo de regress√£o onde:

- a vari√°vel dependente √© o **logaritmo do pre√ßo do im√≥vel**
- as vari√°veis explicativas s√£o **caracter√≠sticas observ√°veis do im√≥vel**
- os coeficientes tenham **interpreta√ß√£o econ√¥mica clara**

Modelo conceitual:

![equation](https://latex.codecogs.com/svg.image?\log(P_i)=\beta_0+\beta_1X_{1i}+\beta_2X_{2i}+\dots+\varepsilon_i)

Onde:
- (P_i) √© o pre√ßo do im√≥vel
- (X) s√£o caracter√≠sticas como √°rea, n√∫mero de quartos, localiza√ß√£o etc.

---

##  Intui√ß√£o econ√¥mica

- Pre√ßos imobili√°rios costumam ser:
  - assim√©tricos
  - heteroced√°sticos
- Trabalhar com **log(pre√ßo)**:
  - aproxima varia√ß√µes percentuais
  - reduz influ√™ncia de outliers
  - facilita interpreta√ß√£o dos coeficientes

Exemplo de interpreta√ß√£o:
> Um coeficiente de 0,05 indica aproximadamente **5% de varia√ß√£o no pre√ßo**
associada a uma varia√ß√£o unit√°ria na covari√°vel.

---

## Problemas prov√°veis

- Esquecer de aplicar log no pre√ßo
- Usar vari√°veis categ√≥ricas sem tratamento
- Interpretar coeficientes como causais
- Avaliar o modelo apenas pelo R¬≤
- Criar um modelo excessivamente complexo

---

##  L√≥gica m√≠nima esperada

1. Carregar os dados reais do CSV
2. Inspecionar e limpar os dados
3. Criar a vari√°vel `log_preco`
4. Selecionar covari√°veis relevantes
5. Separar base de treino e teste
6. Estimar uma regress√£o linear
7. Avaliar o desempenho do modelo
8. Interpretar economicamente os resultados

---

## Snippets √∫teis (pistas)

### Log do pre√ßo
```python
import numpy as np

df["log_preco"] = np.log(df["preco"])
```

---

### Sele√ß√£o de covari√°veis (exemplo)
```python
X = df[["area", "quartos", "banheiros"]]
y = df["log_preco"]
```

---

### Separa√ß√£o treino / teste
```python
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42
)
```

---

### Regress√£o linear
```python
from sklearn.linear_model import LinearRegression

model = LinearRegression()
model.fit(X_train, y_train)
```

---

### Avalia√ß√£o b√°sica
```python
r2 = model.score(X_test, y_test)
```

---

## üìä Visualiza√ß√£o m√≠nima recomendada

```python
import matplotlib.pyplot as plt

plt.scatter(y_test, model.predict(X_test), alpha=0.5)
plt.xlabel("log(pre√ßo observado)")
plt.ylabel("log(pre√ßo previsto)")
plt.plot(y_test, y_test)
plt.show()
```

Objetivo do gr√°fico:
- identificar vi√©s
- avaliar dispers√£o
- discutir limita√ß√µes do modelo

---


